{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to keyspace 'csc8101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster = Cluster()\n",
    "session = cluster.connect('csc8101')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create table for task1\n",
    "- Design of Visits_per_url\n",
    " - Query First: the query made on this table is, return pages by given (Topic,Batchtime,Client id), there is an assumption: no rows count equals 0. In this case, the order of key (Topic,Batchtime,Client id) before (page) can satisfiy the requirement. \n",
    " - Choice of Partition Key and Cluster Key: There is a trade-off between Partition Key and Cluster Key. Partition Key will seprarte the whole tabale into partitions and each will exisit in one or more nodes, and cluster key will order data in one partition. \n",
    "   - If there are too many partition key, the hashing for partition key will have too many conflicts. So I do not use combined partiiton key e.g. (topic Batchtime).\n",
    "   - If we use Batchtime as partition key, then all writing or querying in a period of time will all happened in one partition. That can not take advantage of Cassandra distributed system, which not all nodes or partitions are woring together. So I select Topic as partition keys, and others as cluster key.\n",
    "- the table Visit_per_url_tmp only used in generate dummy data. Not used in spark streamming case.\n",
    " - when generating dummy data, we need to figure out distince users for a given topic and page, so the order of key should be (Topic,batchtime,page) , Clientid. To satisfy this, I duplicate the data in Visits_per_url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f397806a908>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_drop = '''\n",
    "    Drop Table IF EXISTS Visits_per_url\n",
    "'''\n",
    "t1_table = 'CREATE TABLE IF NOT EXISTS Visits_per_url(\\\n",
    "            Batchtime timestamp,\\\n",
    "            Clientid varchar,\\\n",
    "            Topic varchar,\\\n",
    "            Page varchar,\\\n",
    "            count int,\\\n",
    "            PRIMARY KEY(Topic,Batchtime,Clientid,Page)\\\n",
    "            )'\n",
    "session.execute(t1_drop)\n",
    "session.execute(t1_table)\n",
    "t1_tmp_drop = '''\n",
    "    Drop Table IF EXISTS Visits_per_url_tmp\n",
    "'''\n",
    "t1_tmp_table = 'CREATE TABLE IF NOT EXISTS Visits_per_url_tmp(\\\n",
    "            Batchtime timestamp,\\\n",
    "            Clientid varchar,\\\n",
    "            Topic varchar,\\\n",
    "            Page varchar,\\\n",
    "            count int,\\\n",
    "            PRIMARY KEY(Topic,Batchtime,Page,Clientid)\\\n",
    "            )'\n",
    "session.execute(t1_tmp_drop)\n",
    "session.execute(t1_tmp_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design of table 2\n",
    "- According to the query requirement, we need get ordered count by given Topic and Batchtime. In this case we need to define Topic and Batchtime as Partition key and count as cluster key for order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f06f012b0f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_drop = '''\n",
    "    Drop Table IF EXISTS Distinct_user_counts\n",
    "'''\n",
    "t2_table='''\n",
    "            CREATE TABLE IF NOT EXISTS Distinct_user_counts(\n",
    "            Batchtime timestamp,\n",
    "            Topic varchar,\n",
    "            Page varchar,\n",
    "            count int,\n",
    "            PRIMARY KEY((Topic,Batchtime),count,Page)\n",
    "            ) \n",
    "        '''\n",
    "#WITH CLUSTERING ORDER BY (insertion_time DESC);\n",
    "session.execute(t2_drop)\n",
    "session.execute(t2_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User_Batchtime used for ordering batchtime\n",
    "- In task 3, we need to get the most recently time and the past 3 time period. To implement this in Discinct_user_counts table, we need to use distince count which is not suggested. So I choose to build a addition table which stores clientid as parititon key and batchtime as cluster key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f3978078d68>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3_drop='''\n",
    "    Drop Tabel IF EXISTS User_Batchtime\n",
    "'''\n",
    "t3_table='''\n",
    "        CREATE TABLE IF NOT EXISTS User_Batchtime(\n",
    "        Clientid varchar,\n",
    "        Batchtime timestamp,\n",
    "        PRIMARY KEY(Clientid,Batchtime)\n",
    "        )\n",
    "'''\n",
    "#session.execute(t3_drop)\n",
    "session.execute(t3_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### helper function used for generating dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1_insert = '''\n",
    "                INSERT INTO Visits_per_url (Topic,Batchtime,Page,Clientid,count) values (%s,%s,%s,%s,%s)\n",
    "                    '''\n",
    "t1_insert_tmp = '''\n",
    "                INSERT INTO Visits_per_url_tmp (Topic,Batchtime,Page,Clientid,count) values (%s,%s,%s,%s,%s)\n",
    "                    '''\n",
    "def t1_update(time,clientid,topic,page,count):\n",
    "    session.execute(t1_insert,(topic,time,page,clientid,count))\n",
    "    session.execute(t1_insert_tmp,(topic,time,page,clientid,count))\n",
    "\n",
    "    \n",
    "t2_insert = '''\n",
    "                    INSERT into Distinct_user_counts (Batchtime,Topic,count,page) values(%s,%s,%s,%s)\n",
    "'''\n",
    "def t2_update(time,topic,page,count):\n",
    "    session.execute(t2_insert,(time,topic,count,page))\n",
    "    \n",
    "def get_milltime(t):\n",
    "    return int(time.mktime(t.timetuple()) *1000)\n",
    "\n",
    "t1_distinct_client = '''\n",
    "        select count(Clientid) from Visits_per_url_tmp\n",
    "        where Batchtime = %s AND\n",
    "        Topic = %s AND\n",
    "        Page = %s\n",
    "'''\n",
    "def t1_unique_client_count(time,topic,page):\n",
    "    re = session.execute(t1_distinct_client,(time,topic,page))\n",
    "    for row in re:\n",
    "        return row[0]\n",
    "    \n",
    "t3_insert = '''\n",
    "    INSERT into User_Batchtime(Clientid,Batchtime) values (%s,%s)\n",
    "'''\n",
    "\n",
    "def t3_update(clientid,batchtime):\n",
    "    session.execute(t3_insert,(clientid,batchtime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Insert dummy data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_client = 200\n",
    "num_topic = 10\n",
    "num_page = 50\n",
    "num_time = 5\n",
    "verbose = 5000\n",
    "\n",
    "#random params\n",
    "page_access_rate = 0.1\n",
    "page_access_rate_repeat=0.5\n",
    "\n",
    "#first time access rate 0.8 \n",
    "# if access : next access rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495000 / 500000\n"
     ]
    }
   ],
   "source": [
    "total = num_topic*num_page*num_time*num_client\n",
    "current = 0\n",
    "for nt in range(num_time):\n",
    "    for ntopic in range(num_topic):\n",
    "        for npage in range(num_page):\n",
    "            for nclient in range(num_client):\n",
    "                d = datetime.date(2017,1,1+nt)\n",
    "                batchtime = get_milltime(d)\n",
    "                topic = 'Topic'+str(ntopic)\n",
    "                page = 'Page'+str(npage)\n",
    "                clientId = 'Client'+str(nclient)\n",
    "                count = 0\n",
    "                rate = page_access_rate\n",
    "                while (random.random()<rate):\n",
    "                    count+=1\n",
    "                    rate = page_access_rate_repeat\n",
    "                \n",
    "                if count>0:\n",
    "                    t1_update(batchtime,clientId,topic,page,count)\n",
    "                    t3_update(clientId,batchtime)\n",
    "                if current % verbose ==0:\n",
    "                    clear_output()\n",
    "                    print ('%d / %d' %(current,total))\n",
    "                current +=1\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test if insert for table 1 success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(count=50312)\n",
      "Row(count=1049)\n"
     ]
    }
   ],
   "source": [
    "rows = session.execute('SELECT count(*) FROM Visits_per_url')\n",
    "for row in rows:\n",
    "    print (row)\n",
    "rows = session.execute('SELECT count(*) FROM User_Batchtime')\n",
    "for row in rows:\n",
    "    print (row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- insert table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 / 2500\n"
     ]
    }
   ],
   "source": [
    "verbose = 100\n",
    "total = num_topic*num_page*num_time\n",
    "current = 0\n",
    "for nt in range(num_time):\n",
    "    for ntopic in range(num_topic):\n",
    "        for npage in range(num_page):\n",
    "            d = datetime.date(2017,1,1+nt)\n",
    "            batchtime = get_milltime(d)\n",
    "            topic = 'Topic'+str(ntopic)\n",
    "            page = 'Page'+str(npage)\n",
    "            count = t1_unique_client_count(batchtime,topic,page)\n",
    "            t2_update(batchtime,topic,page,count)\n",
    "            if current % verbose ==0:\n",
    "                clear_output()\n",
    "                print ('%d / %d' %(current,total))\n",
    "            current +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(count=2640)\n"
     ]
    }
   ],
   "source": [
    "rows = session.execute('SELECT count(*) FROM Distinct_user_counts')\n",
    "for row in rows:\n",
    "    print (row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TASK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nt = 2\n",
    "ntopic = 7\n",
    "nclient = 5\n",
    "past = 3\n",
    "topn = 10\n",
    "topic = 'Topic'+str(ntopic)\n",
    "clientId = 'Client'+str(nclient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t2_top_n = '''\n",
    "            SELECT * FROM Distinct_user_counts \n",
    "            where Batchtime = %s AND Topic = %s  \n",
    "            order by count DESC limit %s\n",
    "'''\n",
    "def get_top_n(batchtime,topic,n):\n",
    "    rows = session.execute(t2_top_n,(batchtime,topic,n))\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t3_get_rank_batchtime = '''\n",
    "    SELECT Batchtime FROM User_batchtime \n",
    "    where Clientid = %s  \n",
    "    order by Batchtime DESC limit %s\n",
    "'''\n",
    "def get_past_batchtime(clientId,past):\n",
    "    rows = session.execute(t3_get_rank_batchtime,(clientId,past))\n",
    "    return rows\n",
    "t1_get_current_batchtime='''\n",
    "    SELECT Batchtime From Visits_per_url\n",
    "    where Topic = %s \n",
    "    order by Batchtime DESC limit 1\n",
    "'''\n",
    "def get_current_batchtime(topic):\n",
    "    rows = session.execute(t1_get_current_batchtime,[topic])\n",
    "    for row in rows:\n",
    "        return row[0]\n",
    "t1_get_previous = '''\n",
    "        SELECT * FROM Visits_per_url\n",
    "        where Topic = %s AND\n",
    "        Batchtime = %s AND \n",
    "        Clientid = %s\n",
    "'''\n",
    "def get_previous(topic,time,clientid):\n",
    "    rows = session.execute(t1_get_previous,(topic,time,clientid))\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2017, 1, 5, 0, 0), datetime.datetime(2017, 1, 4, 0, 0), datetime.datetime(2017, 1, 3, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "current_time = get_current_batchtime(topic)\n",
    "past_time=[]\n",
    "rows = get_past_batchtime(clientId,past)\n",
    "for row in rows:\n",
    "    #print (row.batchtime)\n",
    "    past_time.append(row.batchtime)\n",
    "print (past_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visit_page = set()\n",
    "for i in range(past):\n",
    "    pasttime = past_time[i]\n",
    "    pasttime = get_milltime(pasttime)\n",
    "    rows = get_previous(topic,pasttime,clientId)\n",
    "    for row in rows:\n",
    "        visit_page.add(row.page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recommend = []\n",
    "rows = get_top_n(current_time,topic,topn+len(visit_page))\n",
    "for row in rows:\n",
    "    recommend.append(row.page)\n",
    "new_recommend = [item for item in recommend if item not in visit_page]\n",
    "if(len(new_recommend)>topn):\n",
    "    new_recommend = new_recommend[:topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Page33', 'Page2', 'Page21', 'Page43', 'Page14', 'Page10', 'Page37', 'Page18', 'Page11', 'Page30', 'Page49', 'Page28', 'Page23', 'Page22', 'Page1', 'Page9', 'Page24', 'Page8', 'Page48', 'Page46', 'Page34', 'Page47', 'Page41', 'Page36', 'Page25']\n",
      "{'Page10', 'Page40', 'Page42', 'Page23', 'Page35', 'Page48', 'Page5', 'Page19', 'Page20', 'Page49', 'Page32', 'Page21', 'Page11', 'Page30', 'Page46'}\n",
      "['Page33', 'Page2', 'Page43', 'Page14', 'Page37', 'Page18', 'Page28', 'Page22', 'Page1', 'Page9']\n"
     ]
    }
   ],
   "source": [
    "print(recommend)\n",
    "print(visit_page)\n",
    "print(new_recommend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
