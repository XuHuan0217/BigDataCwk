{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import StringType\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_year count : 12862\n",
      "title_year_distinct_count : 12846 \n",
      "id_title_year_count: 17770\n",
      "id_title_year_distinct_count: 17770\n"
     ]
    }
   ],
   "source": [
    "path_title_year_canonical = 'data/movie_titles_canonical.txt'\n",
    "path_id_title_year = 'data/netflix_movie_titles.txt'\n",
    "title_year = sc.textFile(path_title_year_canonical)\n",
    "id_title_year = sc.textFile(path_id_title_year)\n",
    "print('title_year count : %d' % title_year.count())\n",
    "print('title_year_distinct_count : %d ' % title_year.distinct().count())\n",
    "print('id_title_year_count: %d' % id_title_year.count())\n",
    "print('id_title_year_distinct_count: %d' % id_title_year.distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_year = title_year.distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separate function conver string into tuple\n",
    "- there are \",\" in title, so we cant direct split by \",\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separate_id_year_title(line):\n",
    "    point = [i for i, w in enumerate(line) if w == ','][:2]\n",
    "    return line[:point[0]],line[point[0]+1:point[1]],line[point[1]+1:]\n",
    "\n",
    "def separate_title_year(line):\n",
    "    point = [i for i, w in enumerate(line) if w == ','][-1]\n",
    "    return line[:point],line[point+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create Dataframe and generate title.lower()\n",
    "using Dataframe rather than RDD is because \n",
    "- Dataframe is more convenient to do join on any column with any condition.\n",
    "- Dataframe can name each column, which is better for codign and understanding.\n",
    "- Dataframe is easy to apply functions to specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parts = id_title_year.map(lambda l: separate_id_year_title(l)) \\\n",
    "                     .map(lambda p: (p[0],p[1],p[2],p[2].lower())) \\\n",
    "                     .map(lambda p: Row(id=p[0], year=p[1],title=p[2],clean_title=p[3]))\n",
    "idty_df = spark.createDataFrame(parts)\n",
    "parts = title_year.map(lambda l:separate_title_year(l))\\\n",
    "                  .map(lambda p:(p[0],p[1],p[0].lower()))\\\n",
    "                  .map(lambda p: Row(real_title=p[0],year=p[1],clean_title=p[2]))\n",
    "ty_df = spark.createDataFrame(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert 'N/A' and 'NULL' in year to \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "udf = UserDefinedFunction(lambda year:year if year.isdigit() else '',StringType())\n",
    "idty_df = idty_df.withColumn('year',udf(idty_df.year))\n",
    "ty_df = ty_df.withColumn('year',udf(ty_df.year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first Join with very less modify on them\n",
    "Considering the efficiency, the algorithm first join with less modify on titles. And then select the unmatched title to do fuzzy match which is more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cond = [idty_df.year==ty_df.year,idty_df.clean_title==ty_df.clean_title]\n",
    "join_df1 = idty_df.join(ty_df,cond,'leftouter').select(idty_df.id,idty_df.title,idty_df.year,idty_df.clean_title,ty_df.real_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache matched titles and filter unmatch titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, title: string, year: string, clean_title: string, real_title: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = join_df1.where(join_df1.real_title.isNull()).select(join_df1.id,join_df1.title,join_df1.year,join_df1.clean_title)\n",
    "join_df1 = join_df1.where(join_df1.real_title.isNotNull())\n",
    "join_df1.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unmatched title 14139\n",
      "matched title 3631\n"
     ]
    }
   ],
   "source": [
    "print ('unmatched title %d' % df2.count())\n",
    "print ('matched title %d' %join_df1.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove stop words\n",
    "- try to use stopwords provided by nltk, however, it provides \"too much\" stop words for the title and some title like\"who am I\" will reduce to empty. To solve this problem, I only use three common words the a an as stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#cachedStopWords = stopwords.words(\"english\")\n",
    "cachedStopWords = ['the','a','an']\n",
    "udf = UserDefinedFunction(lambda title: \" \".join([word for word in title.split() if word not in cachedStopWords]) ,StringType())\n",
    "df2 = df2.withColumn('clean_title',udf(df2.clean_title))\n",
    "ty_df = ty_df.withColumn('clean_title',udf(ty_df.clean_title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stemming words \n",
    "- using nltk snowball algorithm to stem word. e.g. boys -> boy, really -> real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer \n",
    "sbs = SnowballStemmer('english',ignore_stopwords=False)\n",
    "udf = UserDefinedFunction(lambda title: \" \".join([sbs.stem(word) for word in title.split()]) ,StringType())\n",
    "df2 = df2.withColumn('clean_title',udf(df2.clean_title))\n",
    "ty_df = ty_df.withColumn('clean_title',udf(ty_df.clean_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove un alphabetic\n",
    "#udf = UserDefinedFunction(lambda title: \" \".join([word for word in title.split() if word.isalpha()]) ,StringType())\n",
    "#df2 = df2.withColumn('clean_title',udf(df2.clean_title))\n",
    "#ty_df = ty_df.withColumn('clean_title',udf(ty_df.clean_title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### second match with clean title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, title: string, year: string, clean_title: string, real_title: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond = [df2.year==ty_df.year,df2.clean_title==ty_df.clean_title]\n",
    "join_df2 = df2.join(ty_df,cond,'leftouter').select(df2.id,df2.title,df2.year,df2.clean_title,ty_df.real_title)\n",
    "join_df2.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filter unmatch title\n",
    "df3 = join_df2.where(join_df2.real_title.isNull()).select(join_df2.id,join_df2.title,join_df2.year,join_df2.clean_title)\n",
    "join_df2 = join_df2.where(join_df2.real_title.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unmatched title 14087\n",
      "matched title 52\n"
     ]
    }
   ],
   "source": [
    "print ('unmatched title %d' % df3.count())\n",
    "print ('matched title %d' %join_df2.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "append = join_df1.union(join_df2)\n",
    "rdd1 = append.select(append.id,append.real_title).rdd.map(lambda x:(x[0],x[1]))\n",
    "#rdd2 = df3.select(df3.id,df3.title).rdd.map(lambda x:(x[0],x[1]))\n",
    "#rdd = rdd1.union(rdd2).cache()\n",
    "rdd = rdd1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcast map(id,title) to all workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b_id_title = sc.broadcast({k:v for (k,v) in rdd.collect()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd.saveAsPickleFile('data/id_title_mapping1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
